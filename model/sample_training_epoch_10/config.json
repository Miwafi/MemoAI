{
    "hidden_size": 768,
    "ffn_hidden_size": 3072,
    "block_count": 12,
    "num_heads": 12,
    "num_kv_heads": 1,
    "rope_dim": 64,
    "rope_base": 10000,
    "vocab_size": 32000,
    "max_seq_length": 512,
    "batch_size": 1,
    "split_valid": 0.01,
    "dropout_rate": 0.1,
    "learning_rate": 0.0002,
    "learning_gamma": 0.95,
    "layer_norm_eps": 1e-06,
    "global_tokens": {
        "<|padding|>": 0,
        "<|unknown|>": 1
    },
    "special_tokens": {
        "<|system|>": 2,
        "<|user|>": 3,
        "<|think|>": 4,
        "<|assistant|>": 5,
        "<|function|>": 6,
        "<|end|>": 7,
        "\\n": 8,
        "WafiGPT": 9,
        "Miwafi": 10
    }
}